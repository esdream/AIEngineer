# 机器学习复习知识点

### 泰勒展开式



### 牛顿法

1. 一元函数牛顿法迭代公式（忽略2次泰勒展开2次以上的项）：

   $x_{t+1} = x_t - \frac {f'(x_t)} {f''(x_t)}$

2. 多元函数牛顿法迭代公式（忽略2次泰勒展开2次以上的项）：

   $x_{k+1} = x_k - H^{-1}_k g_k$

3. 牛顿法的完整流程：

   1. 给定初始值$x_0$和精度阈值$\epsilon$，设置k  = 0
   2. 计算梯度$g_k$和矩阵$H_k$
   3. 如果$||g_k|| < \epsilon$，即在此点处梯度的值接近于0，达到极值点处，停止迭代
   4. 计算搜索方向$d_k = -H^{-1}_k g_k$

   5. 计算新的迭代点$x_{k+1} = x_k + \gamma d_k$

   6. 令 k = k + 1，返回步骤2

      其中$\gamma$是一个人工设定的接近于0的常数，保证$x_{k+1}$在$x_k$的邻域内，从而可以忽略泰勒展开的高次项。如果目标函数是**二次函数**，Hessian矩阵是一个常数矩阵，对于任意给定的初始点，牛顿法只需要一次迭代就可以收敛到极值点。

4. 在实现中，一般不直接求Hessian矩阵的逆矩阵，而是求解下面的线性方程：

   $H_kd = -g_k$

   其解d称为**牛顿方向**。迭代终止的判定依据是梯度值充分接近于0，或者达到最大迭代次数。

5. 牛顿法比梯度下降法收敛速度更快，但每次迭代需要计算Hessian矩阵，求解一个线性方程组，运算量大。如果Hessian矩阵不可逆，该方法失效。

### 凸优化

1. 凸优化的两个限制条件：

   1. 对于目标函数，我们限定是凸函数
   2. 对于优化变量的可行域，我们限定它是凸集

2. 对于n维空间中点的集合C，如果对集合中的任意两点x和y，以及实数 $0 \le \theta\le 1 $，都有

   $\theta x + (1 - \theta) y \in C$

   则该集合称为凸集。如果把这个集合画出来，其边界是凸的，没有凹进去的地方。

### 拉格朗日对偶

1. SVM中的目标函数是最大化间隔分类器与样本的间隔gap。假设间隔分类器的权值为$w$，则目标函数为

   $max \frac {1} {||w||} s.t. , y_i(w^Tx_i + b) \ge 1, i = 1, ... , n$

2. 由于求$\frac {1} {||w||}$的最大值相当于求$\frac {1} {2} ||w||^2$的最小值，所以上述目标函数等价于

   $ min \frac {1} {2} ||w||^2, s.t. , y_i(w^Tx_i + b) \ge 1, i = 1, ... , n $

3. 原始问题



### SVM

1. 高斯核函数

   $f_i  = similarity(x. l^{(i)}) = exp( - \frac {||x - l ^ {i}||^2} {2 \sigma ^ 2})$

2. Softmax函数

   将一个含任意实数的k维向量z压缩到另一个k维实向量$\sigma(z)$中，使得每一个元素的范围都在(0, 1)之间，并且所有元素的和为1。

   $\sigma (z)_j = \frac {e^{z_j}} {\Sigma^k_{K=1}e^{z_k}}, for  j = 1, ..., K$

   其中$z = w_k^Tx$。 

### 高斯分布

1. 一维高斯分布

   $f(x) = \frac {1} {\sigma \sqrt{2 \pi}} exp ( - \frac {(x - \mu) ^ 2} {2 \sigma ^ 2})$

2. 多维高斯分布

   $f_x(x_1, ..., x_k) = \frac {1} {\sqrt{(2 \pi)^k|\Sigma|}} exp ( - \frac {1} {2} (x - \mu)^T \Sigma^{-1}(x - \mu))$

### 回归模型评估

1. 平均绝对值误差（MAE）

   $MAE= \frac {1} {n} \Sigma^n_{i=1}|y_i -  \hat y_i|$

2. 均方误差（MSE）

   $MSE = \frac {1} {n} \Sigma^n_{i=1} (y_i - \hat y_i)^2$

3. R平方值（注意与相关系数中的$R^2$区分）

   $R^2(y, \hat y) = 1 - \frac {\Sigma^{n_{samples} - 1}_{i=0} (y_i - \hat y_i)^2} {\Sigma^{n_{samples} - 1}_{i=0} (y_i - \overline y_i)^2}$ 

   $R^2(y, \hat y)$越接近1，模型越好；越接近0，模型越差。

### 决策树

1. 剪枝思路：使用测试集检测某一节点分裂前后，对测试集拟合结果的差别。

   + 预剪枝：先假定节点不划分，计算测试集拟合结果，再计算划分后测试集拟合结果，比较决定是否剪枝。
   + 后剪枝：先生成完整决策树，在比较去除某一分支节点后，拟合结果的变化决定是否剪枝。

   一般情况下，**后剪枝**决策树的欠拟合风险很小，泛化性能往往优于先预剪枝。

2. 缺失值处理：为每个样本x赋予一个权重$w_x$，如果X在划分属性a上取值未知，则将x同时划入所有子结点，且计算信息增益时，使用样本权值计算，这就是让一个样本以**不同概率**划分到不同的子结点中去，详细见《机器学习》P87。

3. Bagging

   采用自助采样法（bootstrap sampling），有放回地采样，不被采样到的样本比例如下公式，最终得到一个约为初始训练集**63.2%**的train dataset。不被采样的样本作为测试集。

   $lim_{m \to \infty} (1 - \frac {1} {m}) ^ m \to \frac 1 e \approx 0.368$

4. 随机森林（Random Forest）

   在Bagging基础上发展出来。传统决策树在选择划分属性时是在当前结点的属性结合中选择一个最优属性；而在RF中，对基决策树的每个结点，先从该结点的属性集合中**随机选择一个包含k个属性的子集**，然后再从中选择一个最优属性划分。推荐值$k  = log_2d$。

