# 机器学习复习知识点

### 泰勒展开式

用g(x)去逼近f(x)，前面n项为展开项，最后一项（n+1项）为拉格朗日余项。当$x$无限接近$x_0$时，余项是$(x - x_0)^n$的高阶无穷小。其中$\epsilon \in (x_0, x)$，即最后一项可以在$(x_0, x)$之间任意位置展开。

$f(x) = g(x) = g(x_0) + \frac {f^1(x_0)} {1!}(x - x_0) + \frac {f^2(x_0)} {2!}(x - x_0) ^ 2 + ... + \frac {f^n(x_0)} {n!}(x - x_0) ^ n + \frac {f^{n+1}(\epsilon)} {(n+1)!}(x - x_0) ^ {n+1}$  

### 牛顿法

1. 一元函数牛顿法迭代公式（忽略2次泰勒展开2次以上的项）：

   $x_{t+1} = x_t - \frac {f'(x_t)} {f''(x_t)}$

2. 多元函数牛顿法迭代公式（忽略2次泰勒展开2次以上的项）：

   $x_{k+1} = x_k - H^{-1}_k g_k$

3. 牛顿法的完整流程：

   1. 给定初始值$x_0$和精度阈值$\epsilon$，设置k  = 0
   2. 计算梯度$g_k$和Hessian矩阵$H_k$
   3. 如果$||g_k|| < \epsilon$，即在此点处梯度的值接近于0，达到极值点处，停止迭代
   4. 计算搜索方向$d_k = -H^{-1}_k g_k$

   5. 计算新的迭代点$x_{k+1} = x_k + \gamma d_k$

   6. 令 k = k + 1，返回步骤2

      其中$\gamma$是一个人工设定的接近于0的常数，保证$x_{k+1}$在$x_k$的邻域内，从而可以忽略泰勒展开的高次项。如果目标函数是**二次函数**，Hessian矩阵是一个常数矩阵，对于任意给定的初始点，牛顿法只需要一次迭代就可以收敛到极值点。

4. 在实现中，一般不直接求Hessian矩阵的逆矩阵，而是求解下面的线性方程：

   $H_kd = -g_k$

   其解d称为**牛顿方向**。迭代终止的判定依据是梯度值充分接近于0，或者达到最大迭代次数。

5. 牛顿法比梯度下降法收敛速度更快，但每次迭代需要计算Hessian矩阵，求解一个线性方程组，运算量大。如果Hessian矩阵不可逆，该方法失效。

### 凸优化

1. 凸优化的两个限制条件：

   1. 对于目标函数，我们限定是凸函数
   2. 对于优化变量的可行域，我们限定它是凸集

2. 对于n维空间中点的集合C，如果对集合中的任意两点x和y，以及实数 $0 \le \theta\le 1 $，都有

   $\theta x + (1 - \theta) y \in C$

   则该集合称为凸集。如果把这个集合画出来，其边界是凸的，没有凹进去的地方。

### 拉格朗日对偶

1. SVM中的目标函数是最大化间隔分类器与样本的间隔gap。假设间隔分类器的权值为$w$，则目标函数为

   $max \frac {1} {||w||} s.t. , y_i(w^Tx_i + b) \ge 1, i = 1, ... , n$

2. 由于求$\frac {1} {||w||}$的最大值相当于求$\frac {1} {2} ||w||^2$的最小值，所以上述目标函数等价于

   $ min \frac {1} {2} ||w||^2, s.t. , y_i(w^Tx_i + b) \ge 1, i = 1, ... , n $

3. 原始问题



### SVM

1. 高斯核函数

   $f_i  = similarity(x. l^{(i)}) = exp( - \frac {||x - l ^ {i}||^2} {2 \sigma ^ 2})$

2. Softmax函数

   将一个含任意实数的k维向量z压缩到另一个k维实向量$\sigma(z)$中，使得每一个元素的范围都在(0, 1)之间，并且所有元素的和为1。

   $\sigma (z)_j = \frac {e^{z_j}} {\Sigma^k_{K=1}e^{z_k}}, for  j = 1, ..., K$

   其中$z = w_k^Tx$。 

### 高斯分布

1. 一维高斯分布

   $f(x) = \frac {1} {\sigma \sqrt{2 \pi}} exp ( - \frac {(x - \mu) ^ 2} {2 \sigma ^ 2})$

2. 多维高斯分布

   $f_x(x_1, ..., x_k) = \frac {1} {\sqrt{(2 \pi)^k|\Sigma|}} exp ( - \frac {1} {2} (x - \mu)^T \Sigma^{-1}(x - \mu))$

### 回归模型评估

1. 平均绝对值误差（MAE）

   $MAE= \frac {1} {n} \Sigma^n_{i=1}|y_i -  \hat y_i|$

2. 均方误差（MSE）

   $MSE = \frac {1} {n} \Sigma^n_{i=1} (y_i - \hat y_i)^2$

3. R平方值（注意与相关系数中的$R^2$区分）

   $R^2(y, \hat y) = 1 - \frac {\Sigma^{n_{samples} - 1}_{i=0} (y_i - \hat y_i)^2} {\Sigma^{n_{samples} - 1}_{i=0} (y_i - \overline y_i)^2}$ 

   $R^2(y, \hat y)$越接近1，模型越好；越接近0，模型越差。

### 决策树

1. 剪枝思路：使用测试集检测某一节点分裂前后，对测试集拟合结果的差别（《机器学习》上的方法）。

   + 预剪枝：先假定节点不划分，计算测试集拟合结果，再计算划分后测试集拟合结果，比较决定是否剪枝。
   + 后剪枝：先生成完整决策树，在比较去除某一分支节点后，拟合结果的变化决定是否剪枝。

   一般情况下，**后剪枝**决策树的欠拟合风险很小，泛化性能往往优于先预剪枝。

   在《统计学习方法》中，有更详细的对剪枝的数学描述（P65起）。

   #### ID3/C4.5剪枝

   决策树的剪枝往往通过极小化决策树整体的损失函数（loss function）实现。设树T的叶节点个数为|T|，t是树T的叶结点，该叶结点有$N_t$个样本点，其中k类样本点有$N_{tk}$个，k = 1, 2, ..., K。$H_t(T)$为叶结点t上的经验熵。$\alpha \ge 0$为参数。则决策树学习的损失函数可以定义为：

   $$C_{\alpha}(T) = \Sigma^{|T|}_{t=1}N_tH_t(T) + \alpha|T|$$

   其中经验熵为

   $H_t(T) = -\Sigma_k \frac {N_{tk}} {N_T} log \frac {N_{tk}} {N_T}$

   令

   $C(T) = \Sigma^{|T|}_{t=1}N_tH_t(T) = -\Sigma^{|T|}_{t=1}\Sigma_k \frac {N_{tk}} {N_T} log \frac {N_{tk}} {N_T}$

   则有

   $C_{\alpha}(T) = C(T) + \alpha|T|$

   其中$C(T)$表示模型对训练数据的**预测误差（如这里的经验熵（条件熵））**，$|T|$表示模型复杂度，参数$\alpha \ge 0$控制两者之间的影响，这里的$\alpha$是**人为确定**的，较大的$\alpha$促使选择较简单的模型，较小的$\alpha$促进选择较复杂的模型。

   #### CART剪枝

   + 核心思想：**第一步依据训练集，先生成初始决策树$T_0$。然后做t次裁剪（t为叶子结点个数），每次只剪掉一个叶子结点（例如叶子结点共3个ABC，先剪掉A，保留B，C；再剪掉B，保留A，C），计算$\alpha = \frac {C(t) - C(T_t)} {|T_t| -1 }$, 取最小的那个$\alpha$对应的结点，剪掉，生成第一个子树$T_1$。重复以上步骤，直到最后只剩下根节点，作为最后一个子树。得到子树序列$T_0, T_1, ..., T_n$，最后使用验证集对所有子树做一个prediction，取误差最小的子树和对应的$\alpha$**。

   + 具体步骤：

     输入：CART算法生成的决策树$T_0$。

     输出：最优决策树$T_{\alpha}$。

     (1) 设k = 0，$T = T_0$.

     (2) 设$\alpha = + \infty$.

     (3) 自下而上地对各内部结点t计算$C(T_t)$，$|T|$以及

     $g(t) = \frac {C(t) - C(T_t)} {|T_t| -1 }$

     $\alpha = min(\alpha, g(t))$

     这里$g(t)$表示**误差增益（剪枝前后损失函数相等时，求解得到的$\alpha$）**，$T(t)$表示以t为根结点的子树，$C(T_t)$是对训练数据的预测误差，$|T_t|$是$T_t$的叶结点个数。

     (4) 自上而下地访问内部结点t，如果有$g(t) = \alpha$，进行剪枝，并对叶结点t以多数表决法决定其类，得到树T。

     (5) 设$k = k + 1, \alpha_k = \alpha, T_k = T$。

     (6) 如果T不是由根结点单独构成的树，则回到步骤(4)。

     (7) 采用交叉验证法在子树序列$T_0, T_1, ..., T_n$中选取最优子树$T_{\alpha}$。 

     与ID3/C4.5剪枝不同的是，CART剪枝的$\alpha$不是人为确定的，而是遍历各个决策树方案得到的。

2. 缺失值处理：为每个样本x赋予一个权重$w_x$，如果X在划分属性a上取值未知，则将x同时划入所有子结点，且计算信息增益时，使用样本权值计算，这就是让一个样本以**不同概率**划分到不同的子结点中去，详细见《机器学习》P87。

3. Bagging

   采用自助采样法（bootstrap sampling），有放回地采样，不被采样到的样本比例如下公式，最终得到一个约为初始训练集**63.2%**的train dataset。不被采样的样本作为测试集。

   $lim_{m \to \infty} (1 - \frac {1} {m}) ^ m \to \frac 1 e \approx 0.368$

4. 随机森林（Random Forest）

   在Bagging基础上发展出来。传统决策树在选择划分属性时是在当前结点的属性结合中选择一个最优属性；而在RF中，对基决策树的每个结点，先从该结点的属性集合中**随机选择一个包含k个属性的子集**，然后再从中选择一个最优属性划分。推荐值$k  = log_2d$。

