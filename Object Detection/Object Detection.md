## R-CNN

### Pre knowledge

参考[RCNN- 将CNN引入目标检测的开山之作](https://zhuanlan.zhihu.com/p/23006190?refer=xiaoleimlnote)。

1. 重叠度（IOU）

   Bounding box是标注物体的框体，IOU就是ground truth bounding box 与 Inference bounding box的重叠面积占二者并集的面积比例。

   ![IOU = (A∩B) / (A∪B)](https://pic1.zhimg.com/80/v2-6fe13f10a9cb286f06aa1e3e2a2b29bc_hd.jpg)

2. 非极大值抑制（NMS）

   算法会从一张图片中找出n个可能是物体的矩形框，需要判断哪些有用。算法步骤如下：

   + 对所有框按分类是否**属于指定类的概率**从小到大排序。
   + 从**最大概率**的矩形框开始，分别判断n - 1个框与最大概率框的**重叠度IOU**是否**大于某个设定的阈值**。超过阈值的框除去，保留最大阈值的框并标记。
   + 从剩下的框中再选取概率最大的框，然后重复第二步。一直到找到所有被保留下来的矩形框。

### 步骤

1. 候选区域生成：一张图像生成1K-2K个候选区域（使用Select Search方法）
   + Select Search 方法：
     1. 首先基于[Efficient GraphBased Image Segmentation](http://cs.brown.edu/~pff/segment/)（[笔记 - 基于图的图像分割](https://blog.csdn.net/ttransposition/article/details/38024557)）方法得到region。
     2. 使用贪心策略，计算每两个相邻的区域的**相似度**，每次合并最相似的两块，直至最终只剩下一张完整的图片。其中每次产生的图像块（包括合并的图像块都保存下来），即可得到图像分层表示。
        + 如何计算两个区域的相似度？需要计算颜色距离（颜色直方图相似）、纹理距离（梯度直方图相似）、给与小区域较高的合并优先级、两个区域的吻合度等，通过加权综合各种距离（详见[Select Search](https://zhuanlan.zhihu.com/p/27467369)）。
     3. 通过以上步骤可以得到很多区域，不同区域作为目标的可能性不同，需要给区域**打分**。给**最先合并的图片块**较大的权重，最后一块完整图像权重为1，倒数第二次合并的权重为2，以此类推。同时权重再乘以一个随机数，按最后得到的结果进行**排序**。
     4. 根据需要选取分数最高的N个候选区域。
2. 特征提取：对每个候选区域，使用**CNN**提取特征。
   + 输入是227 * 227图像，由于selective search得到的是矩形框，paper使用了各向异性缩放（即不管图片长宽比例，缩放即可）。原文中做了padding = 16处理。
   + 使用CNN从每个候选区域中提取一个**固定长度的特征向量（4096维）**。
   + CNN使用AlexNet或VGG16。举例使用AlexNet，参数也使用AlexNet预训练的参数。
   + Fine-tuning训练：假设要检测的物体有N类，则将预训练的CNN模型最后一层替换掉，换成N + 1个输出的神经元（N个类型 + 1个背景类型）。batch size大小为128，其中32个正样本，96个负样本。
     + 正/负样本判断：Select search挑选出来的候选框与ground truth物体框的IOU > 0.5时，则标记为正样本（没有具体类别，只是告诉SVM分类器这里是目标样本，这就是**region proposal**），否则标记为背景类别（负样本）。
3. 类别判断：特征送入每一类的SVM分类器，判断是否属于该类。
   + 将**CNN中输出为正样本**的**候选框**作为SVM分类器的输入。定义候选框与ground truth的IOU**小于0.3**时，标为负样本（背景样本）。
   + 为**每个物体类**训练一个svm分类器。建设我们用CNN提取2000个候选框，可以得到2000 * 4096这样的特征向量矩阵，然后我们只需要把这样的一个矩阵与svm权值矩阵4096 * N点乘(N为分类类别数目，因为我们训练的N个svm，每个svm包含了4096个权值w)，即可得到分类结果。
   + 使用**非极大值抑制（NMS）**去除多余的框，排序，canny边界检测之后得到bounding-box。
4. 位置精修：使用回归器修正候选框的位置。
   + 对每一类目标，使用一个**线性脊回归器**进行精修。
   + 正则项λ=10000。 
   + 输入为深度网络pool5层的4096维特征，输出为xy方向的**缩放**和**平移**。 
   + 训练样本：**判定为本类的候选框中**和ground truth重叠面积**大于0.6**的候选框。

## SPP-Net

出自论文《Spatial Pyramid Pooling in Deep ConvolutionalNetworks for Visual Recognition 》。

R-CNN存在一些性能瓶颈：

+ 速度瓶颈。Selective Search对每张图像产生2k个region proposal，意味着一幅图片需要经过2k次完整的CNN才能得到最终结果。
+ 性能瓶颈。由于输入使用了各向异性缩放，会导致图像**几何畸变**。但由于全连接层中需要固定的输入尺寸，不能使用任意尺度的未经缩放的图像。

###  解决全连接层处理不同尺寸输入的思路

使用**SPM（Spaital Pyramid Matching）**方式。将一副图像分成若干尺度的一些块，比如将一副图像分成1份，4份，8份等，然后将每一块特征融合到一起，就可以得到多个尺度的特征。

![空间金字塔池化层](https://pic1.zhimg.com/v2-62c008799df798656236258c64082340_r.jpg)

上图的空间金字塔池化层是SPPNet的核心，其主要目的是对于任意尺寸的输入产生固定大小的输出。思路是对于任意大小的feature map首先分成16、4、1个块，然后在每个块上最大池化，池化后的特征拼接得到一个固定维度的输出。以满足全连接层的需要所以输入的图像为**一整副图像**。

### 多尺度训练

为了能够**更快地收敛**，paper中采用了**多尺度训练**的方法：使用两个尺寸（224 * 224和180 * 180）的图像训练。180 * 180的图像通过224 * 224缩放得到。之后交替训练，用224的图像训练一个epoch，用180的图像训练一个epoch。

这里使用不同size的图像训练时，全连接层之前的最后一层金字塔池化层中，window_size和stride_size这两个参数由输入图像的size决定。

令conv5出来后特征图的size为a * a，金字塔池化层的size为n * n。则

window_size = [a / n]向上取整。

stride_sizes = [a / n]向下取整。

例如对于pool 3 * 3（这里就不是指的是池化层本身size，而是输出时pool的小块的个数），input image size = 224 * 224，经过5层卷积后feature map为 13 * 13，有

widnows_size = [13 / 3]向上取整 = 5

stride = [13 / 3]向下取整 = 4

同理，当input image size = 180 * 180，经过5层卷积后feature map为 10 * 10，有

widnows_size = [10 / 3]向上取整 = 4

stride = [10 / 3]向下取整 = 3

这样在两种尺度下的SSP后，输出特征维度都是(9 + 4 + 1) * 256，256是feature map个数（channels）。参数是共享的，之后连接全连接层即可。

### Mapping a Window to Feature Maps

在原图中的proposal,经过多层卷积之后，位置还是相对于原图不变的（如下图所示），那现在需要解决的问题就是，如何能够将原图上的proposal,映射到卷积之后得到的特征图上，因为在此之后我们要对proposal进行金字塔池化。

![卷积后特征图中特征位置](https://pic3.zhimg.com/80/v2-523707e94ccb850ca4c23cc94054a144_hd.jpg)

假设$(x, y)$是输入图像上的坐标，$(x', y')$是feature map上的坐标，则映射关系如下：

左上角：$x' = [x / S] + 1$，x / S向下取整

右下角：$x' = [x / S] - 1$，x / S向上取整

其中S为之前**所有层stride的乘积**。

### 分类

最后得到的feature map中的proposal特征框，与在R-CNN中一样，送入SVM中进行分类。

### 存在的不足

和RCNN一样，SPP也需要训练CNN提取特征，然后训练SVM分类这些特征。需要巨大的存储空间，并且分开训练也很复杂。而且selective search的方法提取特征是在CPU上进行的，相对于GPU来说还是比较慢的。