---
title: 数据结构与算法——july
tags: 数据结构, 算法, DSA
grammar_cjkRuby: true
---

## 算法初步

1. 算法的特性：
  + 有穷性
  + 确定性
  + 可行性
  + 输入&输出
    算法不一定有输入，但一定有输出。

2. 常用算法
  + 穷举（万能算法）
    	例如求N个数的全排列、8皇后问题
  + 分而治之（减而治之）
    	例如二分查找、归并排序
  + 贪心
    	最小生成树Prim、Kruskal，但愿最短路径Dijkstra
  + 动态规划
    	背包问题、士兵路径

3. 复杂度
    但算法必须谈复杂度。在实现之前，我们要预估算法所需要的资源（时间、空间）。

4. 时空复杂度
    使用大O记号（最坏情况，忽略常系数）
    时间复杂度：**基本操作次数（汇编指令条数）**
    空间复杂度：占用**内存字节数**
    区别：空间可以再利用，而时间花费了就不可以再利用
    思路：时空互换（hash表）

5. 常见算法的时间复杂度
  + **快速排序的最坏时间复杂度是$O(n^2)$，期望时间复杂度是O(nlogn)**

  + O(1)
    基本运算，加减乘除余，寻址

  + O(logn) 【不同底的log可以通过换底公式相互转化，因此相互只差一个常数】
    二分查找

    换底公式：$log_an * log_ca = log_cn$，其中a, c为常数

  + $O(\sqrt{n})$
    枚举约数

  + O(n)
    线性查找

  + $O(n^2)$
    朴素最近点对

  + $O(n^3)$
    Floyd最短路径
    普通矩阵乘法

  + O(nlogn)
    归并排序
    快速排序的**期望复杂度**
    基于**比较排序**的算法下界

  + $O(2^n)$
    枚举**全部的子集**

  + O(n!)
    枚举**全排列**

6. 常见时间复杂度分析方法
  + 输入输出
  + 数循环次数
  + 均摊分析
  + 多个操作，一起算时间复杂度
    MULTIPOP的队列，可以一次性出队k个元素，每个元素只出入队列一次
    动态数组尾部插入操作，一旦元素超过容量限制，则扩大一倍，再复制
    * 等比数列求和公式：$S_n = (a_1 - a_n * q) / (1 - q)$ 

7. 时间复杂度通常存在一个下限，即输入和输出两者的最大值**max(O(input), O(output))** 。例如要输入n个数，输出$n^2$个数，则时间复杂度的下限是$n^2$。

8. 优化代码一般找**最内层**的循环。

9. 算法涉及累加时优化的思路之一，是将累加改成差。


## 必知必会的数据解构

1. 栈和队列
	+ 存放数据的**线性表**
	+ 操作：入栈/队列，出栈/队列，判断满/空
	+ 空间复杂度：**O(n)**
	+ 单词操作时间复杂度：**O(1)**
	+ 区别：
		+ 栈：先进后出（FILO）
		+ 队列：先进先出（FIFO）

2. 栈和队列的实现
	+ 数组和链表皆可（线性表）
	+ 指针（辅助变量）
		+ 栈顶/底指针
		+ 队头/尾指针

3. 栈的应用：括号匹配检测

4. 栈的应用：模拟系统栈
递归函数的时间、空间复杂度计算：需要先计算递归深度。
生产环境里需要避免使用递归，因为递归深度的判断比较难，一旦系统创建的系统栈超过了系统的上限，就会产生栈溢出。

5. 并查集
	+ 存放数据的集合关系，如`{1, 2} {3, 4} {5}`。
	+ 支持操作
		+ 建立新集合
		+ 查找某个元素属于哪个集合
		+ 合并两个集合
	+ 均摊时间复杂度近似**O(1)**
	+ 并查集的应用：假设n个节点，初始时点与点之间没有连接，给出一系列的连接操作，一次连接操作不产生环，则接受，否则被抛弃。

6. 并查集的实现
+ 存储：使用数组标记每个元素属于的子集。集合中以某个元素作为集合的代表。该元素称为集合的**代表元**。

|属性|点||||||||
|---|---|---|---|---|---|---|---|---|
|index|1|2|3|4|5|6|7|8|
|set|8|2|3|3|5|5|2|8|

+ 合并：直接将根节点属于的子集改变。而根节点的子节点的代表元不需要变化，在查找代表元时，一直向上查找至更新后最新的根节点即可。
+ 查找：从待查找节点倒推至根节点
+ 优化：路径压缩
	路径压缩的操作不是在合并里进行的，而是在**查找**时进行的，当查找某个元素的代表元时，才将查找根节点路径上所有节点的父节点修改称为根节点。这样就分摊了在合并时进行路径压缩的O(n)的复杂度，使得并查集所有操作的时间复杂度近似O(1)。
	
7. 哈希表
	+ 存放数据的集合
	+ 操作：根据`(Key, Value)`进行插入、查找、删除
	+ 空间复杂度：O(m)
	+ 单词操作时间复杂度：O(1)
	+ 本质：Key的索引

8. 哈希表例题
给出n个`[0, m)`范围内的整数，去重
+ 方法1：快速排序
	+ 期望时间复杂度O(nlogn)
	+ 附加空间复杂度O(1)
+ 方法2：计数排序
	+ 时间复杂度O(n + m)
	+ 附加空间复杂度O(m)
	+ 计数排序的原理：计数排序适用的输入元素是**n个i至j之间的整数**。运行时间为Θ(n + (i - j))，i - j是常数，因此可写为O(n + m)。算法步骤如下：
		+ 创建一个长度为i - j的数组C，统计数组中每个值为t的元素出现的次数，存入数组C的第t项。
		+ 对所有的计数累加（从C中的第一个元素开始，每一项和前一项相加）。
		+ 填充目标数组：将每个元素t放在新数组的第C(t)项。每放一个元素将C(t)减1。
例如：排序对象为0, 1, 3, 2, 1, 1, 0。则创建附加数组a并计数得到a为`[2, 3, 1, 1]`。`a[0]`对应0的出现次数为2。计数完成后累加所有计数得到C(t) = 7（排序对象一共7个元素）。然后按照a中的次数填充a的index对应的元素，例如0填充2次，并将C(0)减去2，直至C(t) = 0。最终得到0, 0, 1, 1, 1, 2, 3的排序结果。
	*[计数排序、基数排序、桶排序比较](http://www.cnblogs.com/ttltry-air/archive/2012/08/04/2623302.html)*
	+ 计数排序创建的辅助数组空间可以通过**哈希表**进行压缩。
	+ 哈希表处理冲突（同一个散列表槽内被多个元素指向）的两种处理方法：
		+ **开散列方法**（open hashing，也称为拉链法），把发生冲突的Key存储在散列表主表之外（需要数组和链表）。例如冲突时另开辟一个链表空间，将冲突的Key按照链表顺序依次链接。
		+ **闭散列方法**（close hashing，也称为开地址方法），把发生冲突的Key存储在表中的另一个槽内（只需要数组）。例如冲突时将Key顺序存储至表中的下一个槽内，若存在元素继续往下一个槽中存储。如果整个哈希表存满，需要重新创建更大的哈希表并重新装填。
*[散列的基础知识](http://www.cnblogs.com/huangfox/archive/2012/07/06/2578898.html)*
	+ 评价哈希表：负载率（装填因子） = 已有元素大小 / 存储散列大小，一般负载率保持在50%以下。

9. 哈希表的设计
	+ 哈希函数$H(key) = key\  mod\  p$中的p尽量取**质数**（当然，如果使用斐波那契（Fibonacci）散列法$H(key) = (value * FibNum) >> 28$，则会采用理想乘数，例如32位整数的FibNum为2654435769），保证散列到各个位置的数字个数平衡。

10. 哈希表的删除
分为软删除和硬删除。由于闭散列法中删除一个元素可能会导致该元素后其他元素无法查找，因此一般为软删除。

11. 布隆过滤器
	+ 用于判断一个字符串是否出现过的数据结构
	+ 布隆过滤器使用错误率换空间与时间
	+ 实现方法：
		+ 创建一个由0和1构成的数字序列（可以通过bitmap创建），并初始化为0
		+ 插入：使用k个不同的hash函数计算要插入字符串的Key，将对应的k个位置元素置为1.
		+ 查找：用同样的k个hash函数计算要查找字符串的Key，如果有一个位置为0则该字符串不能存在，全为1时则可能存在
		+ 错误率：随着负载率上升而上升
		+ 无法删除


## 树和堆的定义

1. 树的定义：它是由n(n >= 1)个有限节点组成一个具有层次关系的集合。它具有以下特点：
	+ 每个节点有0个或多个子节点
	+ 没有父节点的节点称为根节点
	+ 每一个非根节点有且只有一个父节点
	+ 除了根节点外，每个子节点可以分为多个不相交的子树

2. 堆的定义：通过构造二叉堆（binary heap），实为二叉树的一种。这种数据解构具有以下性质：
	+ 任意节点小于（或大于）它的**所有后裔**，最小元（或最大元）在堆的**根**上（堆序性）。（两种情况分别称为**最小堆**和**最大堆**）
	+ 堆总是一棵**完全树**，即除了最底层，其他层的节点都被元素填满。且最底层尽可能从左到右填入。

堆的一个经典实现时是**完全二叉树(complete binary tree)** 。
堆的任一子树也是堆。

3. 树的基本操作
	+ 遍历：前中后序遍历（熟悉递归和非递归版本的实现）；层次遍历
	+ 序列化与反序列化
	+ 深度：最大深度、最小深度

4. 堆的基本操作
	+ 插入元素，调整新元素使之满足堆条件
		新插入的节点放在完全二叉树最后的位置，再和父节点比较，如果新节点比父节点小，那么交换两者，然后继续与新的父节点比较，直至new的节点不比父节点小，或者new节点成为根节点。插入操作的复杂度为**O(logn)** 。
	+ 删除元素，调整新元素使之满足堆条件
		删除操作只能删除**根节点**，根节点删除后得到两个子树，基于它们重构堆，进行**percolate_down**操作，让**最后一个节点**last成为新的**根节点**，从而构成一个新的二叉树，再将last节点不断和子节点比较并进行交换，直到last节点不大于任一子节点大小，或者last节点称为叶子节点。删除元素的复杂度为**O(logn)** 。
		
![堆的删除](./images/1519560167588.jpg)

5. 树和堆的应用场景
	+ C++ STL的set与map（红黑树）
	+ 数据库索引（B+树）
	+ 优先队列（堆）
	+ 语法树
	+ 决策树
	+ 游戏场景管理（八叉树或BSP树）

6. 树和堆相关的常用算法
	+ 递归
	+ 分而治之（DAC）
	+ 深度优先搜索
	+ 广度优先搜索

7. `C++`中每种容器类型都定义了自己的迭代器iterator。例如vector。`vector<int>:: iterator iter;`这条语句定义了一个名为iter的变量，它的数据类型是由`vector<int>`定义的iterator类型，使用方法如下：

  ```c++
  vector<int> ivec(10, 1);
  for(vector<int>::iterator iter = ivec.begin(); iter != ivec.end(); ++iter) {
  	...  // 循环中的代码
  }
  ```

8. 二叉搜索树（Binary Search Tree）
二叉搜索树性质如下：
	+ 任一节点n左子树下**每个后代节点**的值都小于节点n的值
	+ 任一节点n右子树下**每个后代节点**的值都大于节点n的值
	+ 任一节点n的左右子树都是二叉搜索树

BST算法查找时间复杂度依赖于树的拓扑结构，最佳情况是O(logn)，最坏情况是O(n)。插入算法与查找算法的复杂度相同（最佳O(logn)，最坏O(n)）。

二叉搜索树有其他变种如AVL树，红黑树，Treap树等。在C++ ，Java的set API中 ，符号表和set的实现一般都是用红黑树。

删除算法需要分多种情况讨论，详见[二叉搜索树](http://www.cnblogs.com/gaochundong/p/binary_search_tree.html)。

9. AVL树

   AVL树是一种特殊的二叉搜索树，要求**任一结点的左子树深度和右子树深度相差不能超过1**。其搜索算法复杂度为$\Theta(log(n))$。

   AVL树在新增一个结点时，调整的基本步骤如下：

   + 按照二叉搜索树的方式增加节点，新增节点称为一个叶节点。

   + 从新增节点开始，回溯到**第一个失衡节点**（即一边子树深度大于另一边子树深度加1）。例如下图中的节点5就是第一个失衡节点。如果回溯到根节点还没有失衡节点，说明该树已经符合AVL性质。

     ![失衡节点](https://images0.cnblogs.com/blog/413416/201303/18231759-1324789a577246eca45489a4daff8440.png)

   + 找到断边（如上图的5 -> 3），确定断边的方向（5的左侧）。

   + 以断边下端（3）为根节点，确定两个子树中哪一个深度更大（左子树还是右子树）。

   + 如果第三步和第四步中的方向一致，都为左子树或都为右子树，则**单旋转以失衡节点为根节点的子树**。否则，**双旋转以失衡节点为根节点的子树**。单/双旋转的方式如下图。

     ![单旋转与双旋转](https://upload.wikimedia.org/wikipedia/commons/c/c7/Tree_Rebalancing.png)

     在代码实现中，平衡检测是通过**平衡因子（balanced factor）**实现的。某个结点的平衡因子等于该节点的左孩子高度减去右孩子的高度。

     + 如果平衡因子是0，1，-1的话，可以认为该节点是符合AVL树定义的。
     + 否则，该节点不平衡，需要重新平衡。

10. B树规则

+ 构建树之前会声明该B树是m阶树（例如m = 5为5阶树，也称为平衡5路查找树）。
+ 树中每个节点最多拥有m个子节点，且m >= 2，空树除外。
+ 除根节点外每个节点的关键字数量大于等于 **ceil(m / 2) - 1** 个，小于等于 **m - 1** 个，非根节点关键字数必须 >= 2。（ceil(x)为向上取整）
+ 所有叶子节点均在同一层，叶子节点除了包含关键字和关键字记录的指针外，也有指向其子节点的指针，不过其指针地址都为**null** 。
+ 如果一个**非叶节点**有**N**个子节点，则该节点的关键字数等于**N - 1**。
+ 所有节点关键字按照**递增**次序排列，并遵循左小右大原则。

11. B+ 树

    相比于B树，更充分利用了节点的空间，查找效率比B树更高、更稳定。

+ B+ 树非叶子节点**不保存**关键字记录的指针，这样B+树每个节点所能保存的关键字大大增加。所以所有的非终端节点可以看成是索引部分。
+ B+ 树**叶子节点**保存了父节点的所有关键字和关键字记录的指针，每个叶子节点的关键字从小到大连接。
+ B+ 树的**根节点关键字数量**和其**子节点个数**相等。

  关于B树、B+ 树相见[从B树、B+树、B*树谈到R 树](https://blog.csdn.net/v_JULY_v/article/details/6530142)。

## 图论

1. 欧拉环路：恰好经过所有的**边**一次
2. 哈米尔顿环路：恰好经过所有的**顶点**一次

3. 图的定义
	 + 描述事物之间的关系
	 + 结点集 V = {v1, v2, ..., vn}
	 + 边集合 E = {e1, e2, ..., em}，其中ei = (vi, vi')
	 + G = <V, E>
	 + 有向图、无向图
	 + 空间复杂度O(n + m)或者$O(n^2)$
	 + 邻接矩阵、邻接表。邻接矩阵的空间复杂度为$O(n^2)$，邻接表由于存在连接时才创建链表空间，因此空间复杂度为O(n + m)。当边很稠密时推荐使用**邻接矩阵**，当边很稀疏时使用**邻接表**。由于存储链表消耗的空间比存储数组消耗的空间大，在**完全图**中，邻接表占用的空间比邻接矩阵大（这是由于存储链表的指针需要额外开辟内存，64位计算机中一个指针的大小是**8个字节**）。
这里我在64位系统上打印`sizeof(int*)`，结果是4。是否因为我的g++编译器是32位的？

4. 拓扑排序：定义
	+ 有向无环图（DAG）
	+ 场景：任务依赖
	+ 时间复杂度O(n + m)

5. 拓扑排序过程
先寻找一个**入度为0**的点，将这个点弹出，将与这个点关联的点的度修改，再重复前面的步骤直至图中没有点为止（如果某一步有多个点入度同时为0，则以上操作可以任选一个进行）。

6. 最短路径问题：定义
	+ 假设E集合（边集）是有权重的
	+ 具象：
		+ V集合代表城市
		+ E集合代表城市间高速路，权重为高速路长度
	+ 两点间存在若干条通路
	+ 长度最短的通路 -> 最短路

7. 最短路：单源最短路
	+ 给定起点s，求到任意点的最短路（Dijkstra）


## 递归

1. 递归问题实际上就是在按层次走一棵树，树的每一个叶子节点就是递归的一个出口。
2. 递归-基本思路
	+ 目标：解决一个规模为n的问题
	+ 思路：
		+ n = 1时，问题很简单
		+ n = 2时，问题也很简单
		+ 如果已经解决了n = k - 1，能否解决n = k
		+ 如果已经解决了n = k / 2，能否解决n = k

3. 递归**空间开销**的大小由递归树的**深度**决定，**时间开销**的大小由递归树的**节点**决定。
4. 递归应用
	+ 计算$n!$, $a^n$，斐波那契数列
	+ 用递归做二分
		+ 快速排序
		+ 归并排序
	+ 用递归做枚举/遍历
		+ 所有可能的枚举、全排列、组合
		+ 树的遍历
		+ 图的遍历
	+ 用递归做状态转移方程
		+ 动态规划的记忆化搜索实现

## 贪心

1. 贪心算法的特点
   1. 解决的问题：最优化问题
   2. 期望通过局部最优解得到全局最优解
   3. 每一步选择：当前最佳
   4. 能得到部分问题的最优解
   5. 能得到部分问题的近似最优解

2. 寻找最大子数列 - **Kadane算法**

   + 问题：给定一个数组例如[-2, 5, 12, -3, -4, -8, 2, 4, 6]，求一个**连续的数列**使得数列内元素的和最大。

   + 算法描述：

     + 遍历数组：在遍历过程中，将遍历的元素依次累加起来，累加结果为当前数列的最大值，当累加结果小于或等于0时，从下一个元素开始，重新开始累加。
     + 累加过程中，用一个变量（max_so_far）记录所获得过的最大值（历史最大值）。
     + 一次遍历后，变量max_so_far中存储的即为最大子数列的和值。

   + C++ 代码

     ```c++
     int maxSubArray(vector<int>& array)
     {
         int len = array.size();
         int maxHere = 0, maxSoFar = 0;
         for(int i = 0; i < len; i++)
         {
             maxHere = 0 > (maxHere += array[i]) ? 0 : maxHere;
             maxSoFar = maxHere > maxSoFar ? maxHere : maxSoFar;
         }
         return maxSoFar;
     }
     ```

3. 背包问题

   分为0 - 1背包问题和部分背包问题。

   0 - 1背包问题不能使用贪心求解（可以使用动态规划），部分背包问题可以使用贪心求解。

## 并发编程基础知识

1. 多任务分为两种形式
   1. **抢占式** ：总控制权在**操作系统**手中，操作系统会轮流询问每一个人物是否需要CPU，需要的话就让他使用，不过一定时间后，操作系统会剥夺当前任务的CPU使用权，把它排在询问队列的最后，再去询问下一个任务。这是目前主流的多任务形式。
   2. **协作式** ：一个任务得到了CPU时间，除非它自己放弃使用CPU，否则将完全霸占CPU，所以任务之间需要协作，使用一段时间CPU后当前任务需要放弃CPU的使用，才能保证系统正常运行。比如早年嵌入式的开发中，由于资源有限，常使用协作式。

2. 同步编程原语（Windows）
   1. 用户态：CriticalSection, SRWLock, InterLocked。速度快，无法命名，无法设置超时，容易卡死。
   2. 内核态：Mutex, Event, Semaphore, AsyncIO。速度慢（用户/内核态切换），可命名，可设置超时。

3. 解决C10K问题（单台服务器要同时支持并发10K量级的连接），可以使用epoll。Windows上使用的是IOCP，是支持多个同时发生的异步I/O操作的程序编程接口。（在Linux中称为epoll，Python中提供了异步IO库 asyncio）

4. 互斥锁的根本目的：将对核心资源的访问串行化。

5. Hadoop和Spark二者的区别

6. 分布式CPA理论

   C：一致性。当一个进程修改了数据之后，其他进程读取的数据要求是更新后的数据。

   A：可用性。用户发出请求，需要实时响应，不能等待其他事情完成才相应。

   P：容错性。一个系统由多个节点组成，部分节点坏了，整个系统能够保证正常通信。

   CPA理论表明：在一个系统中，CPA不能全部满足，只可能最多同时满足两条。

   弱CPA可以满足，比如放弃强一致性而选择最终一致性。比如淘宝大促时的各种限流开关。

7. 为什么要分库分表？

## 博弈论

1. 游戏论
   + 定义：双人（多人）做出多轮决策，每一次决策将影响之后的决策，规则和目标明确。
   + 一般假设所有人都足够聪明
   + 求先手（后手）必胜策略
   + 公平 / 非公平：是否能操控游戏里的所有元素。例如下棋，不能操作对方的棋子，则是非公平的。
   + 平衡态：与终态有一样的性质，无论对手做什么，己方都可以做出相应决策，将终态留给对手。

2. Nim博弈中的先手必胜策略：寻找**必败态**。

   严格定义如下：

   + 无法进行任何移动的局面是必败态。
   + 可以移动非必败态的局面是非必败态。
   + 在必败态做的所有操作的结果都是非必败态。

   对于Nim游戏，局面是必败态当且仅当所有堆硬币的数量都**异或（XOR 符号为$\bigoplus$ ）**起来结果为**0**。

   因此，Nim游戏**先手必胜**策略，只需要保证以下条件：

   + 初始状态为**非必败态**（例如在硬币游戏中，硬币堆数量异或后结果不为0）$a_1 \bigoplus a_2 \bigoplus ... \bigoplus a_n != 0$ 。
   + 先手操作，保证在一次合法移动$a_i \rightarrow a'_i$后, 有**$a_1 \bigoplus a_2 \bigoplus ... a'_i \bigoplus a_n = 0 $ ** ，成为**必败态**（即取走一定数量硬币，使硬币堆数量异或后结果为0）。
   + 后手玩家不论如何移动，必然导致必败态转化为非必败态，先手玩家只需保证每次操作后非必败态都转化为必败态（也就是硬币堆数量异或后结果为0）。

   同理，后手玩家的必胜策略，就是保证初始状态为**必败态**，然后保证先手玩家移动后再将非必败态转化为必败态即可。

3. Nim游戏2：有N个石子，两个人轮流取1, 2, 4, ..., $2^n$个，取最后一个者赢，问先手是否有必胜策略？

   解法：保证初始状态N % 3 != 0，开始取N % 3个，之后取X个，己方取 N - X % 3个，保证余数为0。

## 概率

1. 大数定律

   $$lim_{n\rightarrow \infty}P\{ | \frac {n_x} {n} - p | \lt \epsilon\} = 1$$

2. 条件概率

   **贝叶斯公式**

   $P(A|B) = \frac {P(A)P(B|A)} {P(B)}$

3. 无穷级数

   + **底数小于1**的指数级数一定是收敛的
   + 级数求和$\Sigma^\infty_{n=1}U_n$收敛的**必要条件**是$lim_{n \rightarrow \infty}U_n = 0$ 。即$lim_{n \rightarrow \infty}U_n \ne 0$或不存在时，级数求和$\Sigma^\infty_{n=1}U_n$必发散。这也就解释了 1 - 1 + 1 - 1 + 1 - 1 + ... 是无解的，因为该级数是发散的。发散的级数根本没有求和概念。

## 数论

1. 质因数分解

   + 将N质因数分解：从小到大查找N在[2, Sqrt(N)]上的因数。
   + 查找到第一个最小质因数P。
   + N = N / P，跳回第一步。

   时间复杂度为O(Sqrt(N))，空间复杂度O(1)。

2. 求最大公约数

   辗转相除法（伪代码）

   ```c++
   int gcd(int a, int b)
   {
       if(a == 0) return b;
   	return gcd(b % a, a);
   }
   ```

   时间复杂度**O(logn)**，空间复杂度**O(N)**。

3. 最小公倍数：LCM(a, b) = a * b / gcd(a, b)。

4. 筛法：求[2, N]范围内所有质数。

   + 将[2, N]所有整数加入集合A。
   + 取出最小的整数P，删去A中P的倍数。
   + P一定是A内最小的质数，然后挑下一个整数，跳回（2）。

   时间复杂度**O(NlnlnN)**，空间复杂度**O(N)**。

5. 求约数个数

   求N的约数个数

   + 质因数分解

6. mod运算

   mod运算的一些性质

   + (a + b) % m = (a % m + b % m) % m
   + (a + b) % m = (a % m) * ( b % m) % m
   + 交换律：(a + b) % m = (b + a) % m

   + 结合律：(a + b + c) % m = (a + (b + c)) % m

   + 分配律：(a + b) * c % m = (ac + bc) % m